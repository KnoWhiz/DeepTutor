```bash
# Interactive mode
conda activate deeptutor
python openai_file_api_test.py

# Test mode
python test_chatbot.py
```

# Azure OpenAI PDF Chatbot

A terminal-based chatbot that analyzes PDF files using Azure OpenAI's Assistants API with file search capabilities. It provides responses with source citations based on the uploaded PDF content.

## Features

- üì§ Upload multiple PDF files to Azure OpenAI
- ü§ñ Create an AI assistant with file search capabilities
- üí¨ Interactive terminal chat interface
- üì° **Streaming and non-streaming response modes**
- üìù Source citations for each response
- üßπ Proper error handling and cleanup
- üìä Logging for debugging and monitoring

## Requirements

### Environment Variables

Create a `.env` file in your project root with:

```env
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
```

### Python Dependencies

```bash
pip install openai python-dotenv
```

## Usage

### Interactive Mode

Run the main script to start an interactive chat session:

```bash
conda activate deeptutor
python openai_file_api_test.py
```

**New**: You'll be prompted to choose between streaming and non-streaming modes:

```bash
üîÑ Enable streaming responses? (y/n) [default: n]:
```

- **Streaming mode (y)**: Responses appear character by character as they're generated
- **Non-streaming mode (n)**: Complete responses appear all at once (default)

### Test Mode

Run the test script to verify functionality:

```bash
python test_chatbot.py
```

### Customizing PDF Files

Edit the `pdf_files` list in the `main()` function of `openai_file_api_test.py`:

```python
def main():
    # Add your PDF files here
    pdf_files = [
        "/path/to/your/first.pdf",
        "/path/to/your/second.pdf",
        # Add more files as needed
    ]
    # ... rest of the function
```

## How It Works

1. **File Upload**: PDFs are uploaded to Azure OpenAI with the "assistants" purpose
2. **Vector Store**: A vector store is created to enable semantic search across documents
3. **Assistant Creation**: An AI assistant is created with file search capabilities
4. **Response Mode Selection**: Choose between streaming or non-streaming responses
5. **Chat Session**: Interactive terminal session where you can ask questions
6. **Citations**: Responses include source citations from the analyzed documents
7. **Cleanup**: Resources are automatically cleaned up after the session

## Streaming vs Non-Streaming Modes

### Streaming Mode (üì° STREAMING)
- **Pros**: 
  - Immediate feedback as response is generated
  - Better user experience for long responses
  - Real-time interaction feel
- **Cons**: 
  - Citations are processed and displayed after the main response
  - Slightly more complex error handling

### Non-Streaming Mode (üí¨ STANDARD)
- **Pros**: 
  - Complete response with processed citations appears together
  - Simpler error handling
  - Traditional chat experience
- **Cons**: 
  - Longer wait time for responses
  - No feedback during response generation

## Example Usage

### Streaming Mode
```
ü§ñ Azure OpenAI PDF Chatbot (üì° STREAMING)
================================================================================

üí¨ You: What is this paper about?

ü§ñ Assistant: This paper discusses multiplexed single photon sources based on quantum dots...
[Response appears character by character as it's generated]

[Processed with citations: This paper discusses multiplexed single photon sources based on quantum dots. [Source: assistant-XYZ123] The research focuses on developing efficient methods...]
```

### Non-Streaming Mode
```
ü§ñ Azure OpenAI PDF Chatbot (üí¨ STANDARD)
================================================================================

üí¨ You: What is this paper about?

ü§ñ Assistant: This paper discusses multiplexed single photon sources based on quantum dots. [Source: assistant-XYZ123] The research focuses on developing efficient methods for generating single photons using semiconductor quantum dots in optical cavities. [Source: assistant-XYZ123]
```

## Commands

- **Ask questions**: Type any question about the PDF content
- **streaming**: Toggle between streaming and non-streaming modes during the session
- **status**: Show current streaming mode
- **help**: Show available commands
- **quit/exit/bye**: End the chat session

## Streaming Mode Details

When streaming is enabled:

1. **Real-time Display**: Text appears as it's generated by the AI
2. **Citation Processing**: After the main response is complete, citations are processed and displayed
3. **Error Handling**: Streaming-specific error handling for connection issues
4. **Toggle Support**: You can switch between modes during a session using the `streaming` command

## File Limitations

- Maximum file size: 512MB per PDF
- Supported format: PDF only
- Maximum pages: 100 pages per request
- Total content: 32MB across all files

## Troubleshooting

### Common Issues

1. **Missing environment variables**: Ensure `.env` file contains `AZURE_OPENAI_API_KEY` and `AZURE_OPENAI_ENDPOINT`
2. **File not found**: Check that PDF file paths are correct and files exist
3. **API errors**: Verify your Azure OpenAI resource has the required model deployments
4. **Timeout errors**: Large PDFs may take longer to process; the script will wait up to 5 minutes
5. **Streaming errors**: If streaming fails, the system will fall back to non-streaming mode

### Streaming-Specific Issues

- **Incomplete responses**: If streaming is interrupted, try switching to non-streaming mode
- **Citation display**: Citations appear after the main response in streaming mode
- **Network issues**: Streaming is more sensitive to network connectivity

### Logs

Check `chatbot.log` for detailed logging information about uploads, processing, and any errors.

## Notes

- The script uses GPT-4o model for optimal performance with file search
- Files are automatically cleaned up after each session
- Vector stores are created fresh for each session
- The assistant uses the 2024-05-01-preview API version
- **Streaming uses the Azure OpenAI streaming API for real-time responses**

## Security

- API keys are loaded from environment variables
- Files are uploaded to Microsoft-managed storage
- All resources are cleaned up after use
- No sensitive data is logged 