HonkaiChat: Companions from Anime that feel alive!
Event driven conversations for engaging companionship in fantasy role-playing
Shilong Guo1, Yueze Liu1,2,*, Yichi Zhang1, Zhaoyang Zhu1, Shaan Om Patel2
1University of Illinois at Urbana-Champaign (UIUC)
2Divergence 2% Research Laboratory
yuezel2@illinois.edu
Abstract
Modern
conversational
agents,
including
anime-themed chatbots, are frequently reactive
and personality-driven but fail to capture the
dynamic nature of human interactions. We pro-
pose an event-driven dialogue framework to ad-
dress these limitations by embedding dynamic
events in conversation prompts and fine-tuning
models on character-specific data.
Evalua-
tions on GPT-4 and comparisons with industry-
leading baselines demonstrate that event-driven
prompts significantly improve conversational
engagement and naturalness while reducing hal-
lucinations. This paper explores the applica-
tion of this approach in creating lifelike chat-
bot interactions within the context of Honkai:
Star Rail, showcasing the potential for dynamic
event-based systems to transform role-playing
and interactive dialogue.
1
Introduction
Modern conversational agents, including anime-
themed chatbots, are frequently reactive and
personality-driven. They rely on carefully tuned
prompt instructions to remain "in-character," re-
sponding to user queries in a way that reflects a set
personality, background, or narrative role. How-
ever, these systems often fail to capture the dy-
namism of everyday human interactions, which
are shaped not only by immediate exchanges but
also by evolving events, contexts, and moods. For
instance, a conversation might be influenced by ear-
lier events such as a fire alarm at work, discovering
a new skill, or admiring a beautiful flower. These
factors shift moods, alter perspectives, and influ-
ence conversational topics. Despite these nuances,
current chatbot systems rarely incorporate such
“life-like” elements, operating instead as static,
context-reactive agents without an evolving inter-
nal state. Existing frameworks attempt to address
*Corresponding author.
conversational depth in distinct ways. For exam-
ple, CharacterLLM[Shao et al., 2023] aligns a per-
sonality more faithfully by using interview-style
questions and refining responses to adhere to spe-
cific traits, though it remains largely reactive to
user prompts. Retrieval-Augmented Generation
(RAG)[Lewis et al., 2020] pipelines incorporate
past conversation logs or external knowledge to
contextualize responses, which improves ground-
ing but lacks proactive narrative development or
a sense of internal “life.” Both approaches result
in user-driven, reactive systems, leaving an unmet
demand for bots that feel "alive"—bots with moti-
vations, event-driven states, and evolving moods.
To address this gap, we explored the use of event-
driven prompts to enhance conversational depth
and engagement. Our approach was tested against
industry-leading models, including Character.AI,
where we used carefully engineered prompts em-
bedding dynamic events to evaluate their effect on
conversational quality. The case study involved
GPT-4 as an evaluator, rating conversations be-
tween two random characters interacting with a
lead character. The results consistently demon-
strated that introducing events significantly en-
hanced engagement, making the interactions feel
more natural and immersive. We also applied this
event-driven framework to a chatbot based on the
popular mobile game Honkai: Star Rail by mi-
HoYo, which has been widely embraced by young
people across multiple regions. In particular, we
brought the character March 7th to life, enabling
her to interact with users in a more human-like man-
ner. To achieve this, we crawled text and dialogue
data from sources like the Honkai: Star Rail Wiki
and pre-trained a Llama 3.1 8b model on the corpus
to instill universal knowledge of the game. Sub-
sequently, we fine-tuned the model with curated
dialogues and character-specific events to shape
March 7th’s personality and responses. Our hy-
pothesis is that seeding conversational agents with
arXiv:2501.03277v1  [cs.CL]  5 Jan 2025
rich, character-specific events and training them to
respond in a character-consistent manner leads to
more engaging, varied, and believable interactions.
The experimental results demonstrated that event-
driven prompts provide a clear improvement in con-
versational quality compared to static or context-
reactive systems. This work highlights the potential
of event-based systems to elevate the immersive ex-
perience of role-playing chatbots, making fantasy
roleplaying feel more at home by bridging the gap
between static responses and the nuanced, evolving
nature of human interactions.
2
Related Work
2.1
CharacterLLM
CharacterLLM proposes a framework of trainable
agents for role-playing which simulates the role
by instilling his/her experiences, characteristics,
and emotions[Shao et al., 2023]. The model is
firstly trained with the memories flashes which
is constructed by the character’s profile data, fol-
lowed by a fine-tune stage which instill the model
of contextual information of the characters. The
main drawback of this framework is that the role
is trained based on profile data which cannot suf-
ficiently represent the whole life and context of
the person. Another drawback of the strategy used
in CharacterLLM experiments is that the model’s
performance is degraded by the vanilla base model
whose pre-training data range in distribution does
not align with the role-specific data.
2.2
Retrieval Augmented Generation
RAG[Lewis et al., 2020] architecture consists of a
retriever and a generation-oriented LLM. It helps
to reduce the problem of hallucinations when us-
ing pure LLM for text generation by combining
the information retrieved from a third source, such
as documents, external data sources, etc. It pro-
vides the generation model a hook to fetch domain-
specific data to improve the quality of prompts. In
the application of a real-time chatbot, the retriever
could be used to fetch relevant background informa-
tion and enable the bot to generate more accurate
and event-focusing responses. The key drawback
of RAG is it takes a longer cost than a pure gen-
eration model due to the retrieval process, and the
model may produce odd responses if the retrieval
results do not fully align with the current events.
2.3
ChatHaruhi
ChatHaruhi[Li et al., 2023a] proposed a complete
role-playing algorithm system to play real charac-
ters from anime or TV during a conversation by
training a LLM to learn the background knowledge,
the personality of the character, and the character’s
linguistic habits. The key idea is to extract as much
of the original script as possible to form the base
memory for a character and search relevant plots
to form a prompt when users input a question. The
main pipeline of our project is inspired by this sys-
tem.
3
Data
Our dataset is centered around the popular game
Honkai: Star Rail, a title that has gained significant
traction within the role-playing community. This
dataset serves as the foundation for testing and
enhancing our prompt augmentation methodology.
3.1
Data Creation and Augmentation
To demonstrate our approach, we tasked GPT with
generating scenarios that were “casual, surprising,
and realistic,” ultimately producing and refining
50 scenarios per character across 26 characters, re-
sulting in 1,300 data points. The process required
extensive grounding in the game’s lore and knowl-
edge base, making it a labor-intensive step. Ad-
ditionally, we incorporated detailed OCEAN and
MBTI personality analyses to better support role-
playing and event generation tasks. For training
the role-playing model specifically tailored to the
character "March 7th," we focused on creating a
dialogue dataset. Due to the novelty of the charac-
ter, there was a lack of pre-existing training texts.
To overcome this, we curated a combination of
in-game dialogues and synthesized content. The
following sections detail the dataset’s sources, col-
lection methods, and preparation.
3.2
Data Sources
The primary data source was the Honkai: Star Rail
Wiki, a fan-maintained repository featuring com-
prehensive lore, character descriptions, and dia-
logue excerpts. We systematically extracted rel-
evant information from the Wiki, focusing on all
textual content related to March 7th. Additional
sources included in-game dialogues (approximately
4,000 lines), which served as the foundation for
generating synthetic conversations. To address the
scarcity of domain-specific content, we used GPT
to generate synthetic dialogues. These conversa-
tions were grounded in Honkai: Star Rail’s nar-
rative universe, ensuring thematic and contextual
consistency. Prompts encouraged GPT to simu-
late discussions about newly created events or lore,
significantly enriching the training dataset.
3.3
Data Augmentation
To expand and refine the dataset, we implemented
the following preprocessing techniques:
• Character Name Masking: Dialogues involv-
ing multiple characters were altered by mask-
ing one character’s name (excluding March
7th) to simulate user input.
This allowed
the model to generate context-appropriate re-
sponses for March 7th, enhancing its conver-
sational adaptability.
• Noise Removal: Non-dialogue artifacts, such
as page formatting remnants or unrelated lore,
were filtered out to maintain dataset quality.
• Dialogue Synthesis:
Building upon the
methodology from the CharacterLLM paper,
we used GPT-4 to extend existing in-game dia-
logues. This approach generated new, themat-
ically consistent conversations that adhered
to Honkai: Star Rail’s narrative and character
profiles. By increasing the volume and diver-
sity of training data, this process addressed
the challenges of limited domain-specific dia-
logue data in gaming contexts.
4
Method
To address the issue of conversation initiation, we
propose fine-tuning language models specifically
for conversation starters. While traditional LLMs
ensure chatbot responses are aligned with the pro-
vided text, they often lack a sense of autonomy, as
chatbots should exhibit their own thought processes
and life experiences that influence their behavior
in short conversations[Li et al., 2023b]. Instead
of simply providing a fixed setting and immediate
context, we suggest incorporating life experiences
and randomly generated events that the agent might
reference during dialogue, much like a natural con-
versation.
4.1
Evaluation of Need
To test out the effectiveness of our method of
prompting, we pitted conversation.ai agents with
each other. In one case, they were given an event
Figure 1: Conversation example starter and reply
that happened during their day, and in another case,
they were not given anything in initializing the con-
versation the events were randomly chosen from
dataset (1). The interestingness is later given to
GPT4 for a multi-dimension metric analysis
4.2
Training our own bot
Dissatisfied with character AI even with the im-
plementation, we looked to see if we can add our
own spin on creating a role-playing agent. We at-
tempted this through 4 stages, though incomplete.
The pre-train stage to read 17 MB of data, then fine-
tune it on only one character’s dialogue to attempt
to mimic that person’s behaviors.
4.3
Training Details
We constructed 2,500 training pairs based on the
existing in-game dialogue dataset from Honkai:
Star Rail. Each input includes background infor-
mation introducing the dialogue scenario and the
conversation context, while the output is a stan-
dard character response. Additionally, we gen-
erated 2,500 more training pairs following char-
acterLLM’s approach of dialogue data augmenta-
tion. We trained our model on a total of 5,000
input samples, using LLaMA 3.1-8B as the base
model. To achieve better performance while consid-
ering computational cost constraints, we employed
half-precision floating-point calculations, LoRA
model[Hu et al., 2021] based on the PEFT library,
and stage 3 zero_optimization. We used a batch
size of 128 and a learning rate of 7e-5. For each
character model, the training was conducted on a
single Nvidia A6000 GPU and took approximately
2 hours to complete.
4.3.1
Retrieval-Augmented Generation
We attempted to use RAG for training, though the
integration was deemed unnecessary as we couldn’t
reach the inference stage where this was relevant.
4.4
Data Construction
4.4.1
Event Generation
We first examined the native capabilities of large
language models (LLMs) to produce events that
could be used as conversation starters. Our prelim-
inary tests revealed that off-the-shelf event gen-
eration is often generic and uninteresting.
To
overcome this, we manually curated a dataset of
1,300 events—about 50 for each of several char-
acters—ensuring that these events varied in scope,
emotional tone, and narrative impact(dataset 1).
Examples include a character discovering a new
coffee-making technique, encountering a mysteri-
ous artifact at work, or observing a rare flower.
4.4.2
Character Reaction Data
To ground the model in a rich fictional universe, we
scraped the Honkai: Star Rail wiki for detailed char-
acter backgrounds, lore, and dialogue lines(dataset
2). This provided the model with context about
characters’ personalities, histories, and thematic
elements. We also supplemented the limited in-
game dialogues (roughly 4,000 lines) with GPT-
generated conversations anchored in the Honkai:
Star Rail universe(dataset 3). These synthetic di-
alogues were created by prompting GPT to imag-
ine how characters would discuss newly generated
events or lore, thus expanding our training corpus.
5
Evaluation & Metrics
In order to evaluate the performance of our model,
we conducted the evaluation on a curated subset of
in-game dialogue text data, specifically a test split
consisting of 200 independent samples (N = 200).
For comparison purposes, we introduced LLaMA
3.1-8b-instruct with a prompt-based approach as
a baseline model. We leveraged a state-of-the-art,
proprietary large language model, GPT-4 (version
released on November 20, 2024, referred to as
"gpt-4o-2024-11-20"), to perform qualitative evalu-
ations of the generated responses. Specifically, for
each data sample, the evaluation setup included the
original context, the corresponding ground-truth
response from the dataset, the response generated
by the baseline (LLaMA 3.1 Instruct), and the re-
sponse generated by our proposed approach. GPT-
4 was tasked with rating the quality of each re-
sponse across five distinct dimensions from 0-10:
• Memorization: The model’s ability to recall
relevant information about the character be-
ing portrayed, including precise and detailed
knowledge about people, events, and objects
associated with the role.
• Values: The model must share the same ob-
jectives and values as the character it portrays,
and possesses a distinctive framework for eval-
uating situations based on the character’s per-
spective, which reflects the character’s prefer-
ences and biases.
• Personality: The model should mimic the
way that the character would think or speak,
such as the speaking style or the tones, and
the emotions and reactions under different cir-
cumstances.
• Hallucination: To maintain believability, it
is crucial to assess the model’s ability to dis-
card knowledge and skills that the character
would not have. For example, when question-
ing an ancient individual about computers, the
character should express a lack of knowledge
rather than discussing the advantages of mod-
ern technology.
• Stability: Models can be brittle to the influ-
ence of pre-training or alignment during pro-
longed periods of acting, resulting in devia-
tions from the intended portrayal. Our ob-
jective is to assess the agent’s stability and
consistency over a relatively long duration,
unaffected by variations in incremental inputs.
5.1
Result
5.1.1
Event driven prompt Engineering
The difference between event-driven dialogue
and casual conversation was not particularly pro-
nounced, partly because GPT assigned similar
scores to most bot conversations. This indicates
that, at first glance, the systems lack noticeable vari-
ability for users. However, we observed that when
no prompt was provided, the bots often defaulted to
starting with “may I ask a question.” While accept-
able in casual conversations, this repetitive opening
Figure 2: The evaluation result of our model vs base
model
could become monotonous over multiple sessions
due to its lack of focus on specific topics. Our
re-alignment though doesn’t immediately increase
sensitivity, provides a framework for generic long-
term interactions.
Figure 3: A typical conversation starter for interacting
with LLMs
6
Analysis
6.1
Reduced Generic Hallucinations
When asked about an “imaginary tree” in the game,
the model no longer fabricated irrelevant details
(e.g., “a tree in London”). Instead, it referenced
the in-game concept of “imaginary force,” aligning
more closely with the Honkai: Star Rail universe.
Figure 4: The scores of conversations for engagement
for with and without events
6.2
Contextual Responses to Events
When prompted with recent events (e.g., “You
scored an important contract with a client.”), the
model showed more appropriate emotional re-
sponses, such as excitement or pride. This indicates
some early success in event-driven mood align-
ment.
7
Future Works
7.1
Maintaining Conversational Focus
Long inputs with extensive character analysis some-
times caused the model to shift from conversation
to a narrative storytelling mode. This suggests we
need better prompt strategies or architectural adjust-
ments to keep the model in a conversation-oriented
state.
7.2
Alignment and Personality Diversity
The model tends to produce “good enough” re-
actions that reflect generic human behavior. We
aspire to achieve more distinct, character-specific
reactions. This likely requires further refinement
of training data, improved fine-tuning techniques,
and possibly reinforcement learning from human
feedback to shape nuanced personality traits.
7.3
Manual tuning
Our current setup requires manual event inspection
for alignment, and our pipeline is also designed
to handle one character at a time. Future steps
includes fine-tuning a bot that provides proficient
event pipelines as well as a one-step framework
from text to LLM output pipeline.
8
Conclusion
Our preliminary experiments show that incorporat-
ing event generation and event-driven reaction pat-
terns into chatbot design can yield more dynamic
and contextually interesting conversations. While
early results are promising—reducing irrelevant
hallucinations and producing more event-sensitive
dialogue—significant work remains. We need bet-
ter alignment, deeper personality imprinting, and
more robust conversational grounding. Further iter-
ations will focus on refining event sets, improving
fine-tuning strategies, and employing user feedback
to shape more authentic, character-specific conver-
sational agents. In the future, this kind of agents
are possible to be integrated as monetary feature to
be incorporated in to a game as player attachment
to fictional characters arise.
References
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li,
S. Wang, and W. Chen. Lora: Low-rank adaptation of
large language models. CoRR, abs/2106.09685, 2021.
URL https://arxiv.org/abs/2106.09685.
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin,
N. Goyal, H. Küttler, M. Lewis, W. tau Yih,
T. Rocktäschel, S. Riedel, and D. Kiela. Retrieval-
augmented generation for knowledge-intensive nlp
tasks. In Advances in Neural Information Processing
Systems (NeurIPS), volume 33, pages 9459–9474.
Curran Associates, Inc., 2020.
URL https:
//proceedings.neurips.cc/paper/2020/file/
6b493230205f780e1bc26945df7481e5-Paper.
pdf.
C. Li, Z. Leng, C. Yan, J. Shen, H. Wang, W. Mi, Y. Fei,
X. Feng, S. Yan, H. Wang, L. Zhan, Y. Jia, P. Wu,
and H. Sun. Chatharuhi: Reviving anime character
in reality via large language model, 2023a. URL
https://arxiv.org/abs/2308.09597.
C. Li, Z. Leng, C. Yan, J. Shen, H. Wang, W. MI, Y. Fei,
X. Feng, S. Yan, H. Wang, L. Zhan, Y. Jia, P. Wu,
and H. Sun. Chatharuhi: Reviving anime character
in reality via large language model, 2023b. URL
https://arxiv.org/abs/2308.09597.
Y. Shao, L. Li, J. Dai, and X. Qiu. Character-llm: A
trainable agent for role-playing, 2023. URL https:
//arxiv.org/abs/2310.10158.
